{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6e4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, \n",
    "                             recall_score, f1_score, matthews_corrcoef,\n",
    "                             confusion_matrix, classification_report)\n",
    "\n",
    "# Model imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae49bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the specific file (not a directory)\n",
    "file_path = \"mushrooms.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"uciml/mushroom-classification\",\n",
    "  file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd83c0",
   "metadata": {},
   "source": [
    "## Dataset Attribute Information\n",
    "\n",
    "### Classes\n",
    "- **edible** = e\n",
    "- **poisonous** = p\n",
    "\n",
    "### Attribute Descriptions\n",
    "\n",
    "| Attribute | Values |\n",
    "|-----------|--------|\n",
    "| **cap-shape** | bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s |\n",
    "| **cap-surface** | fibrous=f, grooves=g, scaly=y, smooth=s |\n",
    "| **cap-color** | brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y |\n",
    "| **bruises** | bruises=t, no=f |\n",
    "| **odor** | almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s |\n",
    "| **gill-attachment** | attached=a, descending=d, free=f, notched=n |\n",
    "| **gill-spacing** | close=c, crowded=w, distant=d |\n",
    "| **gill-size** | broad=b, narrow=n |\n",
    "| **gill-color** | black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y |\n",
    "| **stalk-shape** | enlarging=e, tapering=t |\n",
    "| **stalk-root** | bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=? |\n",
    "| **stalk-surface-above-ring** | fibrous=f, scaly=y, silky=k, smooth=s |\n",
    "| **stalk-surface-below-ring** | fibrous=f, scaly=y, silky=k, smooth=s |\n",
    "| **stalk-color-above-ring** | brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y |\n",
    "| **stalk-color-below-ring** | brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y |\n",
    "| **veil-type** | partial=p, universal=u |\n",
    "| **veil-color** | brown=n, orange=o, white=w, yellow=y |\n",
    "| **ring-number** | none=n, one=o, two=t |\n",
    "| **ring-type** | cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z |\n",
    "| **spore-print-color** | black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y |\n",
    "| **population** | abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y |\n",
    "| **habitat** | grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cbacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MUSHROOM CLASSIFICATION - DATASET OVERVIEW\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum().sum(), \"missing values\")\n",
    "print(df.isna().sum().sum(), \"missing values\")\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(df['class'].value_counts())\n",
    "print(f\"\\nPercentage Distribution:\")\n",
    "print(df['class'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecde9e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA PREPROCESSING\n",
      "======================================================================\n",
      "\n",
      "Target encoding: {'e': np.int64(0), 'p': np.int64(1)}\n",
      "\n",
      "Number of Features after encoding: 22\n",
      "Number of Instances: 8124\n",
      "\n",
      "Features: ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Convert target to binary (0: edible, 1: poisonous)\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "print(f\"\\nTarget encoding: {dict(zip(le_target.classes_, le_target.transform(le_target.classes_)))}\")\n",
    "\n",
    "# Label encode all categorical features\n",
    "label_encoders = {}\n",
    "X_encoded = X.copy()\n",
    "\n",
    "for column in X_encoded.columns:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[column] = le.fit_transform(X_encoded[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "print(f\"\\nNumber of Features after encoding: {X_encoded.shape[1]}\")\n",
    "print(f\"Number of Instances: {X_encoded.shape[0]}\")\n",
    "print(\"\\nFeatures:\", list(X_encoded.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "365af665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 6499\n",
      "Test set size: 1625\n",
      "Training set distribution: [3366 3133]\n",
      "Test set distribution: [842 783]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"Training set distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test set distribution: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cc17268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Calculate all required metrics for a model\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "        'MCC': matthews_corrcoef(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e37e294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12b2af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Logistic Regression\n",
      "   Accuracy: 0.9551\n",
      "   AUC: 0.9822\n",
      "   F1 Score: 0.9531\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# MODEL 1: Logistic Regression\n",
    "# ----------------------------\n",
    "print(\"\\n1. Logistic Regression\")\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000, solver='lbfgs')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_metrics, lr_pred = evaluate_model(lr_model, X_test, y_test, 'Logistic Regression')\n",
    "results.append(lr_metrics)\n",
    "print(f\"   Accuracy: {lr_metrics['Accuracy']:.4f}\")\n",
    "print(f\"   AUC: {lr_metrics['AUC']:.4f}\")\n",
    "print(f\"   F1 Score: {lr_metrics['F1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8494e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Decision Tree Classifier\n",
      "   Accuracy: 1.0000\n",
      "   AUC: 1.0000\n",
      "   F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# MODEL 2: Decision Tree\n",
    "# ----------------------------\n",
    "print(\"\\n2. Decision Tree Classifier\")\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_metrics, dt_pred = evaluate_model(dt_model, X_test, y_test, 'Decision Tree')\n",
    "results.append(dt_metrics)\n",
    "print(f\"   Accuracy: {dt_metrics['Accuracy']:.4f}\")\n",
    "print(f\"   AUC: {dt_metrics['AUC']:.4f}\")\n",
    "print(f\"   F1 Score: {dt_metrics['F1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "286c92c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. K-Nearest Neighbors Classifier\n",
      "   Accuracy: 0.9975\n",
      "   AUC: 1.0000\n",
      "   F1 Score: 0.9975\n",
      "   Accuracy: 0.9975\n",
      "   AUC: 1.0000\n",
      "   F1 Score: 0.9975\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# MODEL 3: K-Nearest Neighbors\n",
    "# ----------------------------\n",
    "print(\"\\n3. K-Nearest Neighbors Classifier\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_metrics, knn_pred = evaluate_model(knn_model, X_test, y_test, 'K-Nearest Neighbors')\n",
    "results.append(knn_metrics)\n",
    "print(f\"   Accuracy: {knn_metrics['Accuracy']:.4f}\")\n",
    "print(f\"   AUC: {knn_metrics['AUC']:.4f}\")\n",
    "print(f\"   F1 Score: {knn_metrics['F1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "214c4b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Naive Bayes Classifier (Gaussian)\n",
      "   Accuracy: 0.9286\n",
      "   AUC: 0.9506\n",
      "   F1 Score: 0.9265\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# MODEL 4: Naive Bayes\n",
    "# ----------------------------\n",
    "print(\"\\n4. Naive Bayes Classifier (Gaussian)\")\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_metrics, nb_pred = evaluate_model(nb_model, X_test, y_test, 'Naive Bayes')\n",
    "results.append(nb_metrics)\n",
    "print(f\"   Accuracy: {nb_metrics['Accuracy']:.4f}\")\n",
    "print(f\"   AUC: {nb_metrics['AUC']:.4f}\")\n",
    "print(f\"   F1 Score: {nb_metrics['F1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9202d192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Random Forest (Ensemble)\n",
      "   Accuracy: 1.0000\n",
      "   AUC: 1.0000\n",
      "   F1 Score: 1.0000\n",
      "   Accuracy: 1.0000\n",
      "   AUC: 1.0000\n",
      "   F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# MODEL 5: Random Forest\n",
    "# ----------------------------\n",
    "print(\"\\n5. Random Forest (Ensemble)\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_metrics, rf_pred = evaluate_model(rf_model, X_test, y_test, 'Random Forest')\n",
    "results.append(rf_metrics)\n",
    "print(f\"   Accuracy: {rf_metrics['Accuracy']:.4f}\")\n",
    "print(f\"   AUC: {rf_metrics['AUC']:.4f}\")\n",
    "print(f\"   F1 Score: {rf_metrics['F1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "295285ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. XGBoost (Ensemble)\n",
      "   Accuracy: 1.0000\n",
      "   AUC: 1.0000\n",
      "   F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# MODEL 6: XGBoost\n",
    "# ----------------------------\n",
    "print(\"\\n6. XGBoost (Ensemble)\")\n",
    "xgb_model = XGBClassifier(random_state=42, n_estimators=100, learning_rate=0.1, \n",
    "                          max_depth=5, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_metrics, xgb_pred = evaluate_model(xgb_model, X_test, y_test, 'XGBoost')\n",
    "results.append(xgb_metrics)\n",
    "print(f\"   Accuracy: {xgb_metrics['Accuracy']:.4f}\")\n",
    "print(f\"   AUC: {xgb_metrics['AUC']:.4f}\")\n",
    "print(f\"   F1 Score: {xgb_metrics['F1']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
